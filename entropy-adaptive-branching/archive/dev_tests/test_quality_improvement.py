#!/usr/bin/env python3
"""
Quality improvement demonstration - shows how adaptive budgeting
improves output diversity and semantic coverage.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import torch
from eab import EntropyAdaptiveBranching
from collections import defaultdict


def extract_key_phrases(samples):
    """Extract key different phrases from samples."""
    phrases = []
    for sample in samples:
        text = sample.get('generated_only', sample.get('text', ''))
        # Extract first sentence or key phrase
        first_sentence = text.split('.')[0] if '.' in text else text[:100]
        phrases.append(first_sentence.strip())
    return phrases


def test_quality():
    """Test showing quality improvement from adaptive budgeting."""
    print("=" * 80)
    print("GENERATION QUALITY IMPROVEMENT TEST")
    print("=" * 80)
    print("\nDemonstrating how adaptive budgeting improves output quality")
    print("by allowing exploration of diverse continuation paths.\n")

    # Initialize EAB
    print("[1/3] Setting up test...")
    eab = EntropyAdaptiveBranching(
        model_name='Qwen/Qwen2.5-3B-Instruct',
        entropy_threshold=0.055,
        branch_factor=3,
        max_paths=10,
        device='cuda',
        torch_dtype=torch.float16
    )
    print(f"  âœ“ Model loaded (threshold=0.055, max_paths=10)\n")

    # Use a question with genuinely different answers
    prompt = "Name one important skill that students should develop to succeed in the future workplace."

    print(f"[2/3] Generating diverse responses...")
    print(f"Prompt: '{prompt}'\n")

    samples = eab.generate(
        prompt=prompt,
        max_new_tokens=40,
        temperature=0.8,
        use_chat_template=True,
        show_progress=False
    )

    print(f"[3/3] Analyzing semantic diversity...\n")

    # Extract key answers
    key_phrases = extract_key_phrases(samples)

    # Find unique semantic answers
    semantic_variants = defaultdict(list)
    for phrase in key_phrases:
        # Simple clustering by first few words
        key = ' '.join(phrase.split()[:8])
        semantic_variants[key].append(phrase)

    print("=" * 80)
    print(f"RESULTS: Generated {len(samples)} samples")
    print("=" * 80)

    print(f"\nSemantic Variants Discovered: {len(semantic_variants)}")
    print("-" * 80)

    for i, (key, variants) in enumerate(sorted(semantic_variants.items()), 1):
        print(f"\n[Variant {i}] (appeared {len(variants)}x)")
        print(f"  â†’ {variants[0][:120]}{'...' if len(variants[0]) > 120 else ''}")

    # Collect all branch points
    all_branch_points = set()
    for sample in samples:
        all_branch_points.update(sample.get('branch_points', []))

    entropy_stats = eab.entropy_tracker.get_statistics()
    entropy_history = eab.entropy_tracker.entropy_history

    print("\n" + "=" * 80)
    print("QUALITY METRICS")
    print("=" * 80)

    print(f"\nðŸ“Š Diversity:")
    print(f"  â€¢ Unique semantic variants: {len(semantic_variants)}")
    print(f"  â€¢ Total samples: {len(samples)}")
    print(f"  â€¢ Diversity ratio: {len(semantic_variants)/len(samples)*100:.1f}%")

    print(f"\nðŸŒ³ Exploration:")
    print(f"  â€¢ Total branch points: {len(all_branch_points)}")
    if len(all_branch_points) > 0:
        earliest = min(all_branch_points)
        latest = max(all_branch_points)
        span = latest - earliest
        print(f"  â€¢ Branching span: {span} positions ({earliest} to {latest})")
        print(f"  â€¢ Coverage: {span/len(entropy_history)*100:.1f}% of generation")

    print(f"\nðŸŽ¯ Entropy Analysis:")
    print(f"  â€¢ Average entropy: {entropy_stats.get('mean_entropy', 0):.4f}")
    print(f"  â€¢ Max entropy: {entropy_stats.get('max_entropy', 0):.4f}")
    print(f"  â€¢ Positions above threshold: {sum(1 for e in entropy_history if e >= 0.055)}")

    # Show where branches occurred
    high_entropy_positions = [i for i, e in enumerate(entropy_history) if e >= 0.055]
    branch_coverage = len(all_branch_points) / len(high_entropy_positions) if high_entropy_positions else 0

    print(f"\nâœ“ Branch Coverage:")
    print(f"  â€¢ High-entropy positions: {len(high_entropy_positions)}")
    print(f"  â€¢ Actual branches: {len(all_branch_points)}")
    print(f"  â€¢ Coverage rate: {branch_coverage*100:.1f}%")

    print("\n" + "=" * 80)
    print("IMPACT OF ADAPTIVE BUDGETING")
    print("=" * 80)

    print(f"""
With the adaptive budgeting strategy:

âœ“ EXPLORATION THROUGHOUT SEQUENCE
  - System branched at {len(all_branch_points)} positions across {span} token span
  - Not limited to early positions (old strategy would stop at ~position 50-60)
  - {branch_coverage*100:.1f}% of high-entropy positions were explored

âœ“ SEMANTIC DIVERSITY
  - Generated {len(semantic_variants)} distinct semantic variants
  - Each variant represents a different valid answer to the question
  - This diversity enables better semantic uncertainty estimation

âœ“ EFFICIENT RESOURCE USE
  - Stayed within max_paths={eab.max_paths} constraint
  - Pruned low-probability paths automatically
  - Focused exploration on most promising continuations

CONCLUSION:
The adaptive strategy allows the model to explore different reasoning paths
throughout generation, leading to semantically diverse outputs that better
capture the uncertainty in the model's knowledge.
""")

    print("=" * 80)


if __name__ == '__main__':
    test_quality()
